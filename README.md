# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

The dataset contains row of 10000 people who were contacted via telephone or cellular. The data contains information about education, age, job, martial status and some other variables. It also contains the variable "y" with "no" and "yes" as values. This seems to be a variable describing some form of success either regarding a marketing campaing or something similar. We will try to predict the outcome of "y" based on the ohter variables.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

The data is prepared by "train.py". A pandas dataframe is created, NULL navules are removed and some variables are formated correctly. Then the data is split into 1/3 testing data and 2/3 training data. We have two hyperparameters to optimize our model with: "C" and "max_iter" and use a logistic regression model as classification model.

**What are the benefits of the parameter sampler you chose?**

I picked a uniform sampler for "C" and a choice sampler for "max_iter". The benefit of this is to provide a defined range in which HypderDrive will then find optimal parameters for the model.

**What are the benefits of the early stopping policy you chose?**

The early stopping policy is usefull to be efficient with ressources. The bandit policy will abort once is seems unlikely that a run will lead to a better solution.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

For AutoML I only define that I want to train  a classification model. AutoML will then try different models and optimize the hyperparameters of these models to find an optimal model  based on the metric I pick.
With my configuration the solution was: "StandardScalerWrapper XGBoostclassifier".

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

With HyperDrive I limit the best possible solution by the model and the random search for parameter values. With my configuration of HyperDrive and the Logistic regression classifier, AutoML was able to find a better solution with the greater degree of freedom. The "accuracy" of the AutoML model was better with a value of 0.9144 than the HyperDrice solution with an accuracy of 0.843.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

The configuration of HyperDrive and AutoML could be optimized by someone with more experience. This way possible better solutions are not avoided from the beginning and other non-optimal solutions are avoided to be more efficient with  ressources. For example the "XGBoostCLassifier" seems to be very dominant to solve this problem with the highest accuracy. It might be worth it to optimize that model annd block alternatives completly.

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
